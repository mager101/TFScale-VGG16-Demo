{"cells":[{"cell_type":"markdown","metadata":{"id":"42Sb7Qw38CQa"},"source":["## Mount Google Drive locally\n","\n","Mount your Google Drive on your runtime using an authorization code\n","\n","(Note: Select \"Connect to Google Drive\" when prompted and sign in with your current Google Drive account)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2442,"status":"ok","timestamp":1647779440163,"user":{"displayName":"mager101","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiF-brM8K-ljPdWGOvgXL7ztKPGMdzOEpvs7cFCHA=s64","userId":"05025975222452400749"},"user_tz":-480},"id":"pLBEGMA573Mf","outputId":"fc5c3047-238e-40c1-9be8-955212af6c75"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","dataset_location = \"/content/drive/MyDrive/TFScale VGG16 Demo/data/\""]},{"cell_type":"markdown","metadata":{"id":"llNMcH5ZgeeC"},"source":["***\n","## Import libraries and initialize values"]},{"cell_type":"markdown","metadata":{"id":"QJxYQ7Wugt6v"},"source":["* Line 16: prepare the ```path``` to the \"data\" folder in the Google Drive\n","* Line 17: define the input image ```dimension``` of the network\n","* Line 18: define the ```Batch Size```\n","* Line 19: define the number of ```Epochs```\n","* Line 24-25: initialize an empty array for ```data``` and ```labels```"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":414,"status":"ok","timestamp":1647781170778,"user":{"displayName":"mager101","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiF-brM8K-ljPdWGOvgXL7ztKPGMdzOEpvs7cFCHA=s64","userId":"05025975222452400749"},"user_tz":-480},"id":"ScQB_ikF8F2W","outputId":"04ca4ef7-ce7b-4327-fb7a-712b4ec7db01"},"outputs":[],"source":["import os\n","import cv2\n","import numpy as np\n","import tensorflow as tf\n","import numpy as np\n","import random\n","from imutils import paths\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.preprocessing.image import img_to_array\n","from tensorflow.keras.applications import vgg16, resnet50\n","from sklearn.preprocessing import LabelBinarizer\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras import models\n","from tensorflow.keras import layers\n","\n","dataset_path = dataset_location\n","IMAGE_DIMS = (224, 224, 3)\n","BS = 32\n","EPOCHS = 50\n","print(\"Tensorflow version %s\"%tf.__version__)\n","print(\"opencv version %s\"%cv2.__version__)\n","\n","# initialize the data and labels\n","data = []\n","labels = []"]},{"cell_type":"markdown","metadata":{"id":"1We2MoQsgupY"},"source":["***\n","## Prepare the input images / data"]},{"cell_type":"markdown","metadata":{"id":"UXt7Dqtsh7Lv"},"source":["* Line 3: obtain the list of image filenames\n","* Line 4-5: shuffle (randomise) the list\n","* Line 8: loop through each image file\n","* Line 10-11: read the image\n","* Line 12: resize the image\n","* Line 13: convert the image from OpenCV format to normal array\n","* Line 14: add the image to the ```data``` array\n","* Line 18: extract the name only from the filename\n","* Line 19: add the name as label into the ```labels``` array"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":315012,"status":"ok","timestamp":1647781487456,"user":{"displayName":"mager101","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiF-brM8K-ljPdWGOvgXL7ztKPGMdzOEpvs7cFCHA=s64","userId":"05025975222452400749"},"user_tz":-480},"id":"KH9xdMRa8g7N","outputId":"cfccd608-5b28-45ae-90d4-c530379fe50d"},"outputs":[],"source":["# grab the image paths and randomly shuffle them\n","print(\"[INFO] loading images...\")\n","imagePaths = sorted(list(paths.list_images(dataset_path)))\n","random.seed(42)\n","random.shuffle(imagePaths)\n","\n","# loop over the input images\n","for ind, imagePath in enumerate(imagePaths):\n","\t# load the image, pre-process it, and store it in the data list\n","\tprint(ind, imagePath, imagePath.split(os.path.sep)[-2])\n","\timage = cv2.imread(imagePath)\n","\timage = cv2.resize(image, (IMAGE_DIMS[1], IMAGE_DIMS[0]))\n","\timage = img_to_array(image)\n","\tdata.append(image)\n"," \n","\t# extract the class label from the image path and update the\n","\t# labels list\n","\tlabel = imagePath.split(os.path.sep)[-2]\n","\tlabels.append(label)\n","print(\"Done!\")"]},{"cell_type":"markdown","metadata":{"id":"1fld4U54jHj4"},"source":["* Line 2: normalize the image\n","* Line 2-3: convert the ```data``` and ```labels``` into *numpy* array\n","* Line 4-5: display the size of the ```data```"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":399,"status":"ok","timestamp":1647782061291,"user":{"displayName":"mager101","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiF-brM8K-ljPdWGOvgXL7ztKPGMdzOEpvs7cFCHA=s64","userId":"05025975222452400749"},"user_tz":-480},"id":"3s_tVNdb9rSq","outputId":"3129866f-25fc-4a59-94c8-d41586326f46"},"outputs":[],"source":["# scale the raw pixel intensities to the range [0, 1]\n","data = np.array(data, dtype=\"float\") / 255.0\n","labels = np.array(labels)\n","print(\"[INFO] data matrix: {:.2f}MB\".format(\n","\tdata.nbytes / (1024 * 1000.0)))"]},{"cell_type":"markdown","metadata":{"id":"knPyZKlZjr1e"},"source":["Neural network is not able to accept string (text) as labels, one-hot enconding is an approach to convert text into integer values.\n","\n","* Line 2-3: Perform one-hot encoding on the ```labels```.\n","\n"]},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1647782062435,"user":{"displayName":"mager101","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiF-brM8K-ljPdWGOvgXL7ztKPGMdzOEpvs7cFCHA=s64","userId":"05025975222452400749"},"user_tz":-480},"id":"Os2OmlKz_QdE"},"outputs":[],"source":["# binarize the labels\n","lb = LabelBinarizer()\n","labels = lb.fit_transform(labels)"]},{"cell_type":"markdown","metadata":{"id":"MGkZSRkNkFY2"},"source":["* Line 3-4: perform train-test split"]},{"cell_type":"code","execution_count":38,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1647782062830,"user":{"displayName":"mager101","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiF-brM8K-ljPdWGOvgXL7ztKPGMdzOEpvs7cFCHA=s64","userId":"05025975222452400749"},"user_tz":-480},"id":"Ha9Xy3X3_TLm"},"outputs":[],"source":["# partition the data into training and testing splits using 80% of\n","# the data for training and the remaining 20% for testing\n","(trainX, testX, trainY, testY) = train_test_split(data,\n","\tlabels, test_size=0.2, random_state=42)"]},{"cell_type":"markdown","metadata":{"id":"Wd_ubXQAxpKS"},"source":["---\n","##**DEMO**\n","##Load Model from Google Drive\n","\n","If you have trained your own model below, make sure that the newly trained model is loaded below."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6202,"status":"ok","timestamp":1647782073024,"user":{"displayName":"mager101","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiF-brM8K-ljPdWGOvgXL7ztKPGMdzOEpvs7cFCHA=s64","userId":"05025975222452400749"},"user_tz":-480},"id":"WXMWcstNWjEA","outputId":"0ef2e8c3-f7c8-48b6-dae9-80f8d930ec9e"},"outputs":[],"source":["loaded_model = tf.keras.models.load_model('/content/drive/MyDrive/TFScale VGG16 Demo/model/plant.h5')\n","loss, acc = loaded_model.evaluate(testX, testY, verbose=2)\n","print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))"]},{"cell_type":"markdown","metadata":{"id":"COecptWdd3-S"},"source":["## Load an image for testing"]},{"cell_type":"markdown","metadata":{"id":"R5NL5dttd3-X"},"source":["* Line 2: load an image\n","* Line 5: resize the image\n","* Line 6: convert to *RGB* for display purpose (OpenCV format is *BGR*)\n","* Line 7: normalise the image\n","* Line 8-9: prepare the image into array"]},{"cell_type":"code","execution_count":40,"metadata":{"executionInfo":{"elapsed":524,"status":"ok","timestamp":1647782125404,"user":{"displayName":"mager101","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiF-brM8K-ljPdWGOvgXL7ztKPGMdzOEpvs7cFCHA=s64","userId":"05025975222452400749"},"user_tz":-480},"id":"YaCT5oCFd3-X"},"outputs":[],"source":["# load the image\n","image = cv2.imread(dataset_path + '/Dill/Dill24.jpg')\n","\n","# pre-process the image for classification\n","image = cv2.resize(image, (IMAGE_DIMS[0], IMAGE_DIMS[1]))\n","image_display = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","image = image.astype(\"float\") / 255.0\n","image = img_to_array(image)\n","image = np.expand_dims(image, axis=0)"]},{"cell_type":"markdown","metadata":{"id":"epR03P9Ld3-X"},"source":["* Line 1-2: import matplotlib and set the output to within colab (inline)\n","* Line 6: Perform classification\n","* Line 7: obtain the ***```index```*** with the highest probability\n","* Line 8: Obtain the label of the ```index```\n","* Line 10-12: display image and predicted label"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":321},"executionInfo":{"elapsed":2633,"status":"ok","timestamp":1647782134397,"user":{"displayName":"mager101","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiF-brM8K-ljPdWGOvgXL7ztKPGMdzOEpvs7cFCHA=s64","userId":"05025975222452400749"},"user_tz":-480},"id":"H0fgyoUAd3-X","outputId":"2f7c8c8f-1dd9-4031-a121-8d0ea262e1be"},"outputs":[],"source":["%matplotlib inline\n","import matplotlib.pyplot as plt\n","\n","# classify the input image\n","print(\"[INFO] classifying image...\")\n","proba = loaded_model.predict(image)[0]\n","idx = np.argmax(proba)\n","label = lb.classes_[idx]\n","\n","plt.imshow(image_display)\n","plt.show()\n","print(label)\n","print(idx)"]},{"cell_type":"markdown","metadata":{"id":"_kBI_df0kSpu"},"source":["***\n","## Prepare the model (using transfer learning)"]},{"cell_type":"markdown","metadata":{"id":"Pf7HRihzkYg2"},"source":["* Line 8: obtain the VGG16 pre-trained model ***without*** the dense classification layers.\n","* Line 11-13: Set all the base pre-trained layer to be ***un-trainable***\n","* Line 36: Create the model and initialise it with the pre-trained layers\n","* Line 43: creating the desnse layers for classification (Note: Ensure that number of dense layers matches the number of plant folders)\n","* Line 49-51: compile the model\n","* Line 57: display a summary of the model\n","\n","(Note: Commented lines are to provide a brief explanation of the line(s) below and may also be code that could be used for training)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p6vheJesAFwb"},"outputs":[],"source":["from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.models import Sequential\n","# initialize the model\n","print(\"[INFO] compiling model...\")\n","\n","# Load VGG16 model without the top layers\n","base_layers = vgg16.VGG16(include_top=False, input_shape=IMAGE_DIMS)\n","\n","# Allow fine tuning to go into the convolution layers 32, 94, 136, 168\n","base_layers_to_train = 0\n","for i in range(0, len(base_layers.layers) - base_layers_to_train):\n","    base_layers.layers[i].trainable = False\n","for i in range(len(base_layers.layers) - base_layers_to_train, len(base_layers.layers)):\n","    base_layers.layers[i].trainable = True\n","    print(\"%s is set trainable\"%base_layers.layers[i].name)\n","\n","base_layers.summary()\n","print(\"total %d layers\"%len(base_layers.layers) )\n","\n","hidden_layers_to_add = [] # No hidden layer\n","#hidden_layers_to_add = [128] # One hidden layer with 128 nodes\n","#hidden_layers_to_add = [128, 64] # Two hidden layers with 128 and 64 nodes respectively\n","\n","# Data augmentation flip, rotate and zoom\n","#data_augmentation = keras.Sequential(\n","#  [\n","#    layers.RandomFlip(\"horizontal\",input_shape=(224,224,3)),\n","#    layers.RandomRotation(0.1),\n","#    layers.RandomZoom(0.1),\n","#  ]\n","#)\n","\n","# Create the network\n","#network = models.Sequential([data_augmentation, base_layers])\n","network = models.Sequential([base_layers])\n","\n","# Add dropout layer\n","#network.add(layers.Dropout(0.2))\n","network.add(layers.Flatten())\n","for node in hidden_layers_to_add:\n","  network.add(layers.Dense(node, activation='sigmoid'))\n","network.add(layers.Dense(10, activation='softmax'))\n","\n","# Compile the model\n","#network.compile(optimizer='rmsprop',\n","#                loss='categorical_crossentropy',\n","#                metrics=['accuracy'])\n","network.compile(optimizer='adam',\n","                loss='categorical_crossentropy',\n","                metrics=['accuracy'])\n","#network.compile(optimizer='sgd',\n","#                loss='categorical_crossentropy',\n","#                metrics=['accuracy'])\n","\n","# Display a summary of the model\n","network.summary()"]},{"cell_type":"markdown","metadata":{"id":"iQU1oP2ql-iF"},"source":["***\n","## Perform training and testing"]},{"cell_type":"markdown","metadata":{"id":"pPZiBAsal79o"},"source":["* Line 2: reducing learning rate over time\n","* Line 3: early stop if the validation loss stops improving\n","* Line 4: perform training\n","* Line 5: perform testing\n","* Line 6: display test result"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AoWahhTOAI0H"},"outputs":[],"source":["%%time\n","reduce = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.1, patience=5, mode='auto')\n","early = keras.callbacks.EarlyStopping(monitor='loss', min_delta=1e-4, patience=10, mode='auto')\n","history = network.fit(trainX, trainY, epochs=EPOCHS, batch_size=BS, verbose=2, callbacks=[reduce, early])\n","test_loss, test_acc = network.evaluate(testX, testY, verbose=2)\n","print('accuracy: {:5.2f}%'.format(100 * test_acc))"]},{"cell_type":"markdown","metadata":{},"source":["## Mapping out results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MXQE3GQ9N3DH"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","acc = history.history['accuracy']\n","#val_acc = history.history['test_acc']\n","\n","loss = history.history['loss']\n","#val_loss = history.history['test_loss']\n","\n","epochs_range = range(EPOCHS)\n","\n","plt.figure(figsize=(8, 8))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs_range, acc, label='Training Accuracy')\n","#plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation Accuracy')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs_range, loss, label='Training Loss')\n","#plt.plot(epochs_range, val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"THTBj2HvxYuZ"},"source":["##Save model to Google Drive"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6EfumqFBWPn8"},"outputs":[],"source":["network.save(\"/content/drive/MyDrive/TFScale VGG16 Demo/model/myplant.h5\")"]},{"cell_type":"markdown","metadata":{"id":"-xN--aXFBfud"},"source":["***\n","## Load an image for testing"]},{"cell_type":"markdown","metadata":{"id":"ym_SaZBlmjEv"},"source":["* Line 2: load an image\n","* Line 5: resize the image\n","* Line 6: convert to *RGB* for display purpose (OpenCV format is *BGR*)\n","* Line 7: normalise the image\n","* Line 8-9: prepare the image into array"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zwgZaZsSAa5U"},"outputs":[],"source":["# load the image\n","image = cv2.imread(dataset_path + '/Dill/Dill24.jpg')\n","\n","# pre-process the image for classification\n","image = cv2.resize(image, (IMAGE_DIMS[0], IMAGE_DIMS[1]))\n","image_display = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","image = image.astype(\"float\") / 255.0\n","image = img_to_array(image)\n","image = np.expand_dims(image, axis=0)"]},{"cell_type":"markdown","metadata":{"id":"2a-8_pV1nOIx"},"source":["* Line 1-2: import matplotlib and set the output to within colab (inline)\n","* Line 6: Perform classification\n","* Line 7: obtain the ***```index```*** with the highest probability\n","* Line 8: Obtain the label of the ```index```\n","* Line 10-12: display image and predicted label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nvcYNgtkEPlM"},"outputs":[],"source":["%matplotlib inline\n","import matplotlib.pyplot as plt\n","\n","# classify the input image\n","print(\"[INFO] classifying image...\")\n","proba = network.predict(image)[0]\n","idx = np.argmax(proba)\n","label = lb.classes_[idx]\n","\n","plt.imshow(image_display)\n","plt.show()\n","print(label)\n","print(idx)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"TFScale VGG16 Demo.ipynb","provenance":[{"file_id":"1Sh_7XEw0ZjwkBgTpyd2ZWhorxxVMJhip","timestamp":1635320622374}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.9.9"}},"nbformat":4,"nbformat_minor":0}
